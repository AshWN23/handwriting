{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepVoice3 single-speaker TTS en demo.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshWN23/handwriting/blob/master/DeepVoice3_single_speaker_TTS_en_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Za124iWvdMsZ"
      },
      "cell_type": "markdown",
      "source": [
        "# DeepVoice3: Single-speaker text-to-speech demo\n",
        "\n",
        "In this notebook, you can try DeepVoice3-based single-speaker text-to-speech (en) using a model trained on [LJSpeech dataset](https://keithito.com/LJ-Speech-Dataset/). The notebook is supposed to be executed on [Google colab](https://colab.research.google.com) so you don't have to setup your machines locally.\n",
        "\n",
        "**Estimated time to complete**: 5 miniutes.\n",
        "\n",
        "- Code: https://github.com/r9y9/deepvoice3_pytorch\n",
        "- Audio samples: https://r9y9.github.io/deepvoice3_pytorch/"
      ]
    },
    {
      "metadata": {
        "id": "ml6wOhwqhGiI"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "QjindPTItq75"
      },
      "cell_type": "markdown",
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "metadata": {
        "id": "kemMMs6pg9Rv"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import exists, join, expanduser\n",
        "\n",
        "# Clone\n",
        "name = \"deepvoice3_pytorch\"\n",
        "if not exists(name):\n",
        "  ! git clone https://github.com/r9y9/$name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntBxf7b6DCqT"
      },
      "cell_type": "code",
      "source": [
        "# Change working directory to the project dir\n",
        "# os.chdir(join(expanduser(\"~\"), name)) # commented out the old line\n",
        "os.chdir(name) # Change to the current directory where the repository was cloned\n",
        "\n",
        "!git checkout 7a10ac6763eda92595e257543494b6a95f64229b --quiet\n",
        "\n",
        "# Install dependencices\n",
        "!pip install -q -e '.[bin]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6VFmDe-ideo"
      },
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "! pip install -q librosa nltk\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "# need this for English text processing frontend\n",
        "import nltk\n",
        "! python -m nltk.downloader cmudict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_l1Gd2SStt0E"
      },
      "cell_type": "markdown",
      "source": [
        "### Download a pre-trained model"
      ]
    },
    {
      "metadata": {
        "id": "42Zwjr4UjNn_"
      },
      "cell_type": "code",
      "source": [
        "preset = \"20180505_deepvoice3_ljspeech.json\"\n",
        "checkpoint_path = \"20180505_deepvoice3_checkpoint_step000640000.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45Wrp8INj6Xu"
      },
      "cell_type": "code",
      "source": [
        "if not exists(preset):\n",
        "  !curl -O -L \"https://www.dropbox.com/s/0ck82unm0bo0rxd/20180505_deepvoice3_ljspeech.json\"\n",
        "if not exists(checkpoint_path):\n",
        "  !curl -O -L \"https://www.dropbox.com/s/5ucl9remrwy5oeg/20180505_deepvoice3_checkpoint_step000640000.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_yJ90ESZiT_S"
      },
      "cell_type": "markdown",
      "source": [
        "## Synthesis"
      ]
    },
    {
      "metadata": {
        "id": "FUyhiJg03dj6"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup hyper parameters"
      ]
    },
    {
      "metadata": {
        "id": "E9sLuYgcnbZb"
      },
      "cell_type": "code",
      "source": [
        "import hparams\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.training.hparams import HParams\n",
        "\n",
        "\n",
        "# Load parameters from preset\n",
        "with open(preset) as f:\n",
        "  preset_content = f.read()\n",
        "  if preset_content:\n",
        "    print(type(preset_content))\n",
        "    print(preset_content)\n",
        "    # Create a new HParams object and parse the JSON content\n",
        "    hp = HParams()\n",
        "    hp.parse_json(preset_content)\n",
        "    # Assign the parsed hparams to the global hparams object\n",
        "    hparams.hparams = hp\n",
        "  else:\n",
        "    print(\"Error: Could not read preset file or file is empty.\")\n",
        "\n",
        "# Inject frontend text processor\n",
        "import synthesis\n",
        "import train\n",
        "from deepvoice3_pytorch import frontend\n",
        "synthesis._frontend = getattr(frontend, \"en\")\n",
        "train._frontend =  getattr(frontend, \"en\")\n",
        "\n",
        "# alises\n",
        "fs = hparams.hparams.sample_rate\n",
        "hop_length = hparams.hparams.hop_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe9ea3f6"
      },
      "source": [
        "# Uninstall the current TensorFlow version\n",
        "!pip uninstall -y tensorflow tensorflow-gpu\n",
        "\n",
        "# Install a compatible TensorFlow version (e.g., 1.15)\n",
        "!pip install tensorflow==1.15 tensorflow-gpu==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2df9f6c"
      },
      "source": [
        "!cat 20180505_deepvoice3_ljspeech.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C4NOldY83wG1"
      },
      "cell_type": "markdown",
      "source": [
        "### Define utility functions"
      ]
    },
    {
      "metadata": {
        "id": "xRbelGLjiSfA"
      },
      "cell_type": "code",
      "source": [
        "def tts(model, text, p=0, speaker_id=None, fast=True, figures=True):\n",
        "  \"\"\"\n",
        "  Synthesizes speech from text using the DeepVoice3 model.\n",
        "\n",
        "  Args:\n",
        "    model: The loaded DeepVoice3 model.\n",
        "    text (str): The input text to synthesize.\n",
        "    p (float, optional): Probability of replacing words with their pronunciation. Defaults to 0.\n",
        "    speaker_id (int, optional): The ID of the speaker for multi-speaker models. Defaults to None.\n",
        "    fast (bool, optional): Whether to use a faster synthesis mode. Defaults to True.\n",
        "    figures (bool, optional): Whether to display attention plot and spectrogram. Defaults to True.\n",
        "\n",
        "  Returns:\n",
        "    None: The function directly displays the audio output.\n",
        "  \"\"\"\n",
        "  from synthesis import tts as _tts\n",
        "  waveform, alignment, spectrogram, mel = _tts(model, text, p, speaker_id, fast)\n",
        "  if figures:\n",
        "      visualize(alignment, spectrogram)\n",
        "  IPython.display.display(Audio(waveform, rate=fs))\n",
        "\n",
        "def visualize(alignment, spectrogram):\n",
        "  label_fontsize = 16\n",
        "  figure(figsize=(16,16))\n",
        "\n",
        "  subplot(2,1,1)\n",
        "  imshow(alignment.T, aspect=\"auto\", origin=\"lower\", interpolation=None)\n",
        "  xlabel(\"Decoder timestamp\", fontsize=label_fontsize)\n",
        "  ylabel(\"Encoder timestamp\", fontsize=label_fontsize)\n",
        "  colorbar()\n",
        "\n",
        "  subplot(2,1,2)\n",
        "  librosa.display.specshow(spectrogram.T, sr=fs,\n",
        "                           hop_length=hop_length, x_axis=\"time\", y_axis=\"linear\")\n",
        "  xlabel(\"Time\", fontsize=label_fontsize)\n",
        "  ylabel(\"Hz\", fontsize=label_fontsize)\n",
        "  tight_layout()\n",
        "  colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a15eceba"
      },
      "source": [
        "# Uninstall any existing TensorFlow installations\n",
        "!pip uninstall -y tensorflow tensorflow-gpu\n",
        "\n",
        "# Install a specific TensorFlow version (e.g., 1.15.0)\n",
        "!pip install tensorflow==1.15.0 tensorflow-gpu==1.15.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c50f9ec6"
      },
      "source": [
        "# Uninstall any existing TensorFlow installations\n",
        "!pip uninstall -y tensorflow tensorflow-gpu\n",
        "\n",
        "# Install a different compatible TensorFlow version (e.g., 1.14)\n",
        "!pip install tensorflow==1.14 tensorflow-gpu==1.14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m2jmbSD430Ws"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the model checkpoint"
      ]
    },
    {
      "metadata": {
        "id": "lr8pgqtYhvav"
      },
      "cell_type": "code",
      "source": [
        "from train import build_model\n",
        "from train import restore_parts, load_checkpoint\n",
        "\n",
        "model = build_model()\n",
        "model = load_checkpoint(checkpoint_path, model, None, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c16ce8dc"
      },
      "source": [
        "!cat train.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be81f8df"
      },
      "source": [
        "!cat hparams.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78d51b74"
      },
      "source": [
        "!cat deepvoice3_pytorch/hparams.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1df6818"
      },
      "source": [
        "!pip install docopt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOJ3miW63ywA"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate speech"
      ]
    },
    {
      "metadata": {
        "id": "GR1XRy-ykbz_"
      },
      "cell_type": "code",
      "source": [
        "# Try your favorite senteneces:)\n",
        "texts = [\n",
        "    \"Scientists at the CERN laboratory say they have discovered a new particle.\",\n",
        "    \"There's a way to measure the acute emotional intelligence that has never gone out of style.\",\n",
        "    \"President Trump met with other leaders at the Group of 20 conference.\",\n",
        "    \"The Senate's bill to repeal and replace the Affordable Care Act is now imperiled.\",\n",
        "    \"Generative adversarial network or variational auto-encoder.\",\n",
        "    \"The buses aren't the problem, they actually provide a solution.\",\n",
        "    \"peter piper picked a peck of pickled peppers how many peppers did peter piper pick.\",\n",
        "    \"Some have accepted this as a miracle without any physical explanation.\",\n",
        "]\n",
        "\n",
        "# Iterate through the list of texts and generate speech for each\n",
        "for idx, text in enumerate(texts):\n",
        "  print(idx, text)\n",
        "  # Call the tts function to synthesize speech\n",
        "  # figures=False means it won't display the attention plot and spectrogram for each sentence\n",
        "  tts(model, text, figures=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d2a3201"
      },
      "source": [
        "!pip install lws"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nirMEf2J5Roy"
      },
      "cell_type": "code",
      "source": [
        "# With attention plot\n",
        "text = \"Generative adversarial network or variational auto-encoder.\"\n",
        "tts(model, text, figures=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eb4f8a5"
      },
      "source": [
        "# Replace '/path/to/your/downloaded/lws.whl' with the actual path or URL of the lws wheel file\n",
        "!pip install /path/to/your/downloaded/lws.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ArQspYbs5Aoo"
      },
      "cell_type": "markdown",
      "source": [
        "For details, please visit https://github.com/r9y9/deepvoice3_pytorch"
      ]
    }
  ]
}